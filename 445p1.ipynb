{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EECS 445 - Winter 2018\n",
    "# Project 1 - project1.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import string\n",
    "import random\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def load_data(fname):\n",
    "    \"\"\"\n",
    "    Reads in a csv file and return a dataframe. A dataframe df is similar to dictionary.\n",
    "    You can access the label by calling df['label'], the content by df['content']\n",
    "    the rating by df['rating']\n",
    "    \"\"\"\n",
    "    return pd.read_csv(fname)\n",
    "\n",
    "\n",
    "def get_split_binary_data():\n",
    "    \"\"\"\n",
    "    Reads in the data from data/dataset.csv and returns it using\n",
    "    extract_dictionary and generate_feature_matrix split into training and test sets.\n",
    "    The binary labels take two values:\n",
    "        -1: poor/average\n",
    "         1: good\n",
    "    Also returns the dictionary used to create the feature matrices.\n",
    "    \"\"\"\n",
    "    fname = \"data/dataset.csv\"\n",
    "    dataframe = load_data(fname)\n",
    "    dataframe = dataframe[dataframe['label'] != 0]\n",
    "    positiveDF = dataframe[dataframe['label'] == 1].copy()\n",
    "    negativeDF = dataframe[dataframe['label'] == -1].copy()\n",
    "    X_train = pd.concat([positiveDF[:500], negativeDF[:500]]).reset_index(drop=True).copy()\n",
    "    dictionary = extract_dictionary(X_train)\n",
    "    X_test = pd.concat([positiveDF[500:700], negativeDF[500:700]]).reset_index(drop=True).copy()\n",
    "    Y_train = X_train['label'].values.copy()\n",
    "    Y_test = X_test['label'].values.copy()\n",
    "    X_train = generate_feature_matrix(X_train, dictionary)\n",
    "    X_test = generate_feature_matrix(X_test, dictionary)\n",
    "\n",
    "    return (X_train, Y_train, X_test, Y_test, dictionary)\n",
    "\n",
    "\n",
    "def get_imbalanced_data(dictionary):\n",
    "    \"\"\"\n",
    "    Reads in the data from data/imbalanced.csv and returns it using\n",
    "    extract_dictionary and generate_feature_matrix as a tuple\n",
    "    (X_train, Y_train) where the labels are binary as follows\n",
    "        -1: poor/average\n",
    "        1: good\n",
    "    Input:\n",
    "        dictionary: the dictionary created via get_split_binary_data\n",
    "    \"\"\"\n",
    "    fname = \"data/imbalanced.csv\"\n",
    "    dataframe = load_data(fname)\n",
    "    dataframe = dataframe[dataframe['label'] != 0]\n",
    "    positiveDF = dataframe[dataframe['label'] == 1].copy()\n",
    "    negativeDF = dataframe[dataframe['label'] == -1].copy()\n",
    "    dataframe = pd.concat([positiveDF[:300], negativeDF[:700]]).reset_index(drop=True).copy()\n",
    "    X_train = generate_feature_matrix(dataframe, dictionary)\n",
    "    Y_train = dataframe['label'].values.copy()\n",
    "\n",
    "    return (X_train, Y_train)\n",
    "\n",
    "\n",
    "def get_imbalanced_test(dictionary):\n",
    "    \"\"\"\n",
    "    Reads in the data from data/dataset.csv and returns a subset of it\n",
    "    reflecting an imbalanced test dataset\n",
    "        -1: poor/average\n",
    "        1: good\n",
    "    Input:\n",
    "        dictionary: the dictionary created via get_split_binary_data\n",
    "    \"\"\"\n",
    "    fname = \"data/dataset.csv\"\n",
    "    dataframe = load_data(fname)\n",
    "    dataframe = dataframe[dataframe['label'] != 0]\n",
    "    positiveDF = dataframe[dataframe['label'] == 1].copy()\n",
    "    negativeDF = dataframe[dataframe['label'] == -1].copy()\n",
    "    X_test = pd.concat([positiveDF[:400], negativeDF[:100]]).reset_index(drop=True).copy()\n",
    "    Y_test = X_test['label'].values.copy()\n",
    "    X_test = generate_feature_matrix(X_test, dictionary)\n",
    "\n",
    "    return (X_test, Y_test)\n",
    "\n",
    "\n",
    "def get_multiclass_training_data():\n",
    "    \"\"\"\n",
    "    Reads in the data from data/dataset.csv and returns it using\n",
    "    extract_dictionary and generate_feature_matrix as a tuple\n",
    "    (X_train, Y_train) where the labels are multiclass as follows\n",
    "        -1: poor\n",
    "         0: average\n",
    "         1: good\n",
    "    Also returns the dictionary used to create X_train.\n",
    "    \"\"\"\n",
    "    fname = \"data/dataset.csv\"\n",
    "    dataframe = load_data(fname)\n",
    "    dictionary = extract_dictionary(dataframe)\n",
    "    X_train = generate_feature_matrix(dataframe, dictionary)\n",
    "    Y_train = dataframe['label'].values.copy()\n",
    "\n",
    "    return (X_train, Y_train, dictionary)\n",
    "\n",
    "\n",
    "def get_heldout_reviews(dictionary):\n",
    "    \"\"\"\n",
    "    Reads in the data from data/heldout.csv and returns it as a feature\n",
    "    matrix based on the functions extract_dictionary and generate_feature_matrix\n",
    "    Input:\n",
    "        dictionary: the dictionary created by get_multiclass_training_data\n",
    "    \"\"\"\n",
    "    fname = \"data/heldout.csv\"\n",
    "    dataframe = load_data(fname)\n",
    "    X = generate_feature_matrix(dataframe, dictionary)\n",
    "    return X\n",
    "\n",
    "\n",
    "def generate_challenge_labels(y, uniqname):\n",
    "    \"\"\"\n",
    "    Takes in a numpy array that stores the prediction of your multiclass\n",
    "    classifier and output the prediction to held_out_result.csv. Please make sure that\n",
    "    you do not change the order of the ratings in the heldout dataset since we will\n",
    "    this file to evaluate your classifier.\n",
    "    \"\"\"\n",
    "    pd.Series(np.array(y)).to_csv(uniqname+'.csv', header=['label'], index=False)\n",
    "    return\n",
    "\n",
    "def select_classifier(penalty='l2', c=1.0, degree=1, r=0.0, class_weight='balanced'):\n",
    "    \"\"\"\n",
    "        Return a linear svm classifier based on the given\n",
    "        penalty function and regularization parameter c.\n",
    "        \"\"\"\n",
    "    # TODO: Optionally implement this helper function if you would like to\n",
    "    # instantiate your SVM classifiers in a single function. You will need\n",
    "    # to use the above parameters throughout the assignment.\n",
    "    if penalty==\"l2\":\n",
    "        return SVC(kernel=\"poly\", C=c, degree=degree, coef0=r, class_weight=class_weight)\n",
    "    if penalty==\"l1\":\n",
    "        return LinearSVC(penalty=\"l1\", C=c, class_weight=class_weight, dual=False)\n",
    "\n",
    "\n",
    "def extract_dictionary(df):\n",
    "    \"\"\"\n",
    "        Reads a panda dataframe, and returns a dictionary of distinct words\n",
    "        mapping from each distinct word to its index (ordered by when it was found).\n",
    "        Input:\n",
    "        df: dataframe/output of load_data()\n",
    "        Returns:\n",
    "        a dictionary of distinct words that maps each distinct word\n",
    "        to a unique index corresponding to when it was first found while\n",
    "        iterating over all words in each review in the dataframe df\n",
    "        \"\"\"\n",
    "    word_dict = {}\n",
    "    \n",
    "    # TODO: Implement this function\n",
    "    index=0\n",
    "    for text in df[\"text\"]:\n",
    "        for p in string.punctuation:\n",
    "            text=text.replace(p,\" \")\n",
    "        text=text.lower()\n",
    "        spl=text.split()\n",
    "        for word in spl:\n",
    "            if word not in word_dict:\n",
    "                word_dict[word]=index\n",
    "                index=index+1\n",
    "    return word_dict\n",
    "\n",
    "\n",
    "def generate_feature_matrix(df, word_dict):\n",
    "    \"\"\"\n",
    "        Reads a dataframe and the dictionary of unique words\n",
    "        to generate a matrix of {1, 0} feature vectors for each review.\n",
    "        Use the word_dict to find the correct index to set to 1 for each place\n",
    "        in the feature vector. The resulting feature matrix should be of\n",
    "        dimension (number of reviews, number of words).\n",
    "        Input:\n",
    "        df: dataframe that has the ratings and labels\n",
    "        word_list: dictionary of words mapping to indices\n",
    "        Returns:\n",
    "        a feature matrix of dimension (number of reviews, number of words)\n",
    "        \"\"\"\n",
    "    number_of_reviews = df.shape[0]\n",
    "    number_of_words = len(word_dict)\n",
    "    feature_matrix = np.zeros((number_of_reviews, number_of_words))\n",
    "    # TODO: Implement this function\n",
    "    index=0\n",
    "    for text in df[\"text\"]:\n",
    "        for p in string.punctuation:\n",
    "            text=text.replace(p,\" \")\n",
    "        text=text.lower()\n",
    "        spl=text.split()\n",
    "        for word in spl:\n",
    "            if word in word_dict:\n",
    "                feature_matrix[index,word_dict[word]]=1\n",
    "        index=index+1\n",
    "    return feature_matrix\n",
    "\n",
    "def cv_performance(clf, X, y, k=5, metric=\"accuracy\"):\n",
    "    \"\"\"\n",
    "        Splits the data X and the labels y into k-folds and runs k-fold\n",
    "        cross-validation: for each fold i in 1...k, trains a classifier on\n",
    "        all the data except the ith fold, and tests on the ith fold.\n",
    "        Calculates the k-fold cross-validation performance metric for classifier\n",
    "        clf by averaging the performance across folds.\n",
    "        Input:\n",
    "        clf: an instance of SVC()\n",
    "        X: (n,d) array of feature vectors, where n is the number of examples\n",
    "        and d is the number of features\n",
    "        y: (n,) array of binary labels {1,-1}\n",
    "        k: an int specifying the number of folds (default=5)\n",
    "        metric: string specifying the performance metric (default='accuracy'\n",
    "        other options: 'f1-score', 'auroc', 'precision', 'sensitivity',\n",
    "        and 'specificity')\n",
    "        Returns:\n",
    "        average 'test' performance across the k folds as np.float64\n",
    "        \"\"\"\n",
    "    # TODO: Implement this function\n",
    "    scores = []\n",
    "    #HINT: You may find the StratifiedKFold from sklearn.model_selection\n",
    "    #to be useful\n",
    "    skf = StratifiedKFold(n_splits=k)\n",
    "    skf.get_n_splits(X,y)\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        if metric==\"auroc\":\n",
    "            y_pred=clf.decision_function(X_test)\n",
    "        score=performance(y_test, y_pred, metric)\n",
    "        scores.append(score)\n",
    "    \n",
    "    #And return the average performance across all fold splits.\n",
    "    return np.array(scores).mean()\n",
    "\n",
    "\n",
    "def select_param_linear(X, y, k=5, metric=\"accuracy\", C_range = [], penalty='l2'):\n",
    "    \"\"\"\n",
    "        Sweeps different settings for the hyperparameter of a linear-kernel SVM,\n",
    "        calculating the k-fold CV performance for each setting on X, y.\n",
    "        Input:\n",
    "        X: (n,d) array of feature vectors, where n is the number of examples\n",
    "        and d is the number of features\n",
    "        y: (n,) array of binary labels {1,-1}\n",
    "        k: int specifying the number of folds (default=5)\n",
    "        metric: string specifying the performance metric (default='accuracy',\n",
    "        other options: 'f1-score', 'auroc', 'precision', 'sensitivity',\n",
    "        and 'specificity')\n",
    "        C_range: an array with C values to be searched over\n",
    "        Returns:\n",
    "        The parameter value for a linear-kernel SVM that maximizes the\n",
    "        average 5-fold CV performance.\n",
    "        \"\"\"\n",
    "    # TODO: Implement this function\n",
    "    #HINT: You should be using your cv_performance function here\n",
    "    #to evaluate the performance of each SVM\n",
    "    maxc=0\n",
    "    maxperf=0\n",
    "    for c in C_range:\n",
    "        clf = select_classifier(penalty=penalty, c=c)\n",
    "        perf = cv_performance(clf, X, y, k=5, metric=metric)\n",
    "        print(c, perf)\n",
    "        if perf>maxperf:\n",
    "            maxperf=perf\n",
    "            maxc=c\n",
    "    return maxc\n",
    "\n",
    "\n",
    "def plot_weight(X,y,penalty,metric=\"\",C_range=[]):\n",
    "    \"\"\"\n",
    "        Takes as input the training data X and labels y and plots the L0-norm\n",
    "        (number of nonzero elements) of the coefficients learned by a classifier\n",
    "        as a function of the C-values of the classifier.\n",
    "        \"\"\"\n",
    "    \n",
    "    print(\"Plotting the number of nonzero entries of the parameter vector as a function of C\")\n",
    "    norm0 = []\n",
    "    \n",
    "    # TODO: Implement this part of the function\n",
    "    #Here, for each value of c in C_range, you should\n",
    "    #append to norm0 the L0-norm of the theta vector that is learned\n",
    "    #when fitting an L2- or L1-penalty, degree=1 SVM to the data (X, y)\n",
    "    \n",
    "    for c in C_range:\n",
    "        clf = select_classifier(penalty=penalty, c=c)\n",
    "        clf.fit(X,y)\n",
    "        n0=0\n",
    "        for c in clf.coef_:\n",
    "            if c!=0:\n",
    "                n0+=1\n",
    "        norm0.append(n0)\n",
    "    \n",
    "    #This code will plot your L0-norm as a function of c\n",
    "    plt.plot(C_range, norm0)\n",
    "    plt.xscale('log')\n",
    "    plt.legend(['L0-norm'])\n",
    "    plt.xlabel(\"Value of C\")\n",
    "    plt.ylabel(\"Norm of theta\")\n",
    "    plt.title('Norm-'+penalty+'_penalty.png')\n",
    "    plt.savefig('Norm-'+penalty+'_penalty.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def select_param_quadratic(X, y, k=5, metric=\"accuracy\", param_range=[]):\n",
    "    \"\"\"\n",
    "        Sweeps different settings for the hyperparameters of an quadratic-kernel SVM,\n",
    "        calculating the k-fold CV performance for each setting on X, y.\n",
    "        Input:\n",
    "        X: (n,d) array of feature vectors, where n is the number of examples\n",
    "        and d is the number of features\n",
    "        y: (n,) array of binary labels {1,-1}\n",
    "        k: an int specifying the number of folds (default=5)\n",
    "        metric: string specifying the performance metric (default='accuracy'\n",
    "        other options: 'f1-score', 'auroc', 'precision', 'sensitivity',\n",
    "        and 'specificity')\n",
    "        parameter_values: a (num_param, 2)-sized array containing the\n",
    "        parameter values to search over. The first column should\n",
    "        represent the values for C, and the second column should\n",
    "        represent the values for r. Each row of this array thus\n",
    "        represents a pair of parameters to be tried together.\n",
    "        Returns:\n",
    "        The parameter value(s) for a quadratic-kernel SVM that maximize\n",
    "        the average 5-fold CV performance\n",
    "        \"\"\"\n",
    "    # TODO: Implement this function\n",
    "    # Hint: This will be very similar to select_param_linear, except\n",
    "    # the type of SVM model you are using will be different...\n",
    "    \n",
    "    maxc=0\n",
    "    macr=0\n",
    "    maxperf=0\n",
    "    for c,r in param_range:\n",
    "        clf=select_classifier(c=c, degree=2, r=r)\n",
    "        perf=cv_performance(clf, X, y, k=k, metric=metric)\n",
    "        if perf>maxperf:\n",
    "            maxc=c\n",
    "            maxr=r\n",
    "            maxperf=perf\n",
    "    return maxc, maxr\n",
    "\n",
    "\n",
    "def performance(y_true, y_pred, metric=\"accuracy\"):\n",
    "    \"\"\"\n",
    "        Calculates the performance metric as evaluated on the true labels\n",
    "        y_true versus the predicted labels y_pred.\n",
    "        Input:\n",
    "        y_true: (n,) array containing known labels\n",
    "        y_pred: (n,) array containing predicted scores\n",
    "        metric: string specifying the performance metric (default='accuracy'\n",
    "        other options: 'f1-score', 'auroc', 'precision', 'sensitivity',\n",
    "        and 'specificity')\n",
    "        Returns:\n",
    "        the performance as an np.float64\n",
    "        \"\"\"\n",
    "    # TODO: Implement this function\n",
    "    # This is an optional but very useful function to implement.\n",
    "    # See the sklearn.metrics documentation for pointers on how to implement\n",
    "    # the requested metrics.\n",
    "\n",
    "    if metric==\"auroc\":\n",
    "        return metrics.roc_auc_score(y_true,y_pred)\n",
    "    m=metrics.confusion_matrix(y_true,y_pred)\n",
    "    tp,fn,fp,tn=m[0,0],m[0,1],m[1,0],m[1,1]\n",
    "    if metric==\"accuracy\":\n",
    "        return (tp+tn)/(tp+tn+fp+tn)\n",
    "    if metric==\"f1-score\":\n",
    "        pre=tp/(tp+fp)\n",
    "        sen=tp/(tp+fn)\n",
    "        return 2*pre*sen/(pre+sen)\n",
    "    if metric==\"sensitivity\":\n",
    "        return tp/(tp+fn)\n",
    "    if metric==\"precision\":\n",
    "        return tp/(tp+fp)\n",
    "    if metric==\"specificity\":\n",
    "        return tn/(tn+fp)\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Read binary data\n",
    "    # NOTE: READING IN THE DATA WILL NOT WORK UNTIL YOU HAVE FINISHED\n",
    "    #       IMPLEMENTING generate_feature_matrix AND extract_dictionary\n",
    "    X_train, Y_train, X_test, Y_test, dictionary_binary = get_split_binary_data()\n",
    "    IMB_features, IMB_labels = get_imbalanced_data(dictionary_binary)\n",
    "    IMB_test_features, IMB_test_labels = get_imbalanced_test(dictionary_binary)\n",
    "    \n",
    "    # TODO: Questions 2, 3, 4\n",
    "    # average count of non-zero features\n",
    "    \n",
    "    # q2\n",
    "    print(\"Number of unique words:\",len(X_train[0]))\n",
    "    print(\"Average number of non-zero features:\",np.sum(X_train)/len(X_train))\n",
    "    \n",
    "    #q3.1(c)\n",
    "    metrics=[\"accuracy\",\"f1-score\",\"auroc\",\"precision\",\"sensitivity\",\"specificity\"]\n",
    "    selected_C=0\n",
    "    C_range=[1e-3, 1e-2, 0.1,1,10,100,1000]\n",
    "    for me in metrics:\n",
    "        maxc=select_param_linear(X_train, y_train, metric=me, C_range = C_range)\n",
    "        clf=select_classifier(c=maxc)\n",
    "        score=cv_performance(clf, X_train, y_train, metric=me)\n",
    "        print(\"C=\",maxc,\"is optimal under\",me,\"metric, cv_perf=\",score)\n",
    "        if me==\"auroc\":\n",
    "            selected_C=maxc\n",
    "    \n",
    "    #q3.1(d)\n",
    "    clf=select_classifier(c=selected_C)\n",
    "    clf.fit(X_train)\n",
    "    y_pred = clf.decision_function(X_test)\n",
    "    auroc_score=performance(y_test, y_pred, metric=\"auroc\")\n",
    "    print(\"q3.1(d) Choose C which maximizes AUROC\")\n",
    "    print(\"The AUROC score is:\",auroc_score)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    for me in metrics:\n",
    "        if me!=\"auroc\":\n",
    "            score=performance(y_test, y_pred, metric=me)\n",
    "            print(\"The\",me,\"score is\",score)\n",
    "\n",
    "    #q3.1(e)\n",
    "    plot_weight(X_train, y_train, \"l2\", C_range=C_range)\n",
    "\n",
    "    #q3.1(f)\n",
    "    clf = select_classifier(c=0.1)\n",
    "    clf.fit(X_train,y_train)\n",
    "    arg=clf.coef_.argsort()\n",
    "    min_ind4=arg[:4]\n",
    "    max_ind4=arg[:-5:-1]\n",
    "    minwords=[]\n",
    "    maxwords=[]\n",
    "    \n",
    "    for ind in min_ind4:\n",
    "        for word, index in dictionary_binary.items():\n",
    "            if index==ind:\n",
    "                minwords.append(word)\n",
    "    print(\"Most negative words\")\n",
    "    for i in range(4):\n",
    "        print(clf.coef_[min_ind4[i]], minwords[i])\n",
    "    \n",
    "    \n",
    "    for ind in max_ind4:\n",
    "        for word, index in dictionary_binary.items():\n",
    "            if index==ind:\n",
    "                maxwords.append(word)\n",
    "    print(\"Most positive words\")\n",
    "    for i in range(4):\n",
    "        print(clf.coef_[max_ind4[i]], maxwords[i])\n",
    "    \n",
    "    #q3.2(a)\n",
    "    r_range=[1e-3, 1e-2, 0.1, 1, 10, 100, 1000]\n",
    "    cr_range=[]\n",
    "    for c in C_range:\n",
    "        for r in r_range:\n",
    "            cr_range.append([c,r])\n",
    "    [maxc,maxr]=select_param_quadratic(X_train, y_train, param_range=cr_range)\n",
    "    print(\"q3.2(a)\")\n",
    "    print(\"C=\",maxc,\"r=\",maxr,\"is optimal\")\n",
    "\n",
    "    #q3.2(b)\n",
    "    cr_range=[]\n",
    "    for i in range(25):\n",
    "        lgc=random.uniform(-3,3)\n",
    "        lgr=random.uniform(-3,3)\n",
    "        cr_range.append([10**lgc, 10**lgr])\n",
    "    [maxc,maxr]=select_param_quadratic(X_train, y_train, param_range=cr_range)\n",
    "    print(\"q3.2(b)\")\n",
    "    print(\"C=\",maxc,\"r=\",maxr,\"is optimal\")\n",
    "    \n",
    "    #q3.4(a)\n",
    "    maxc=0\n",
    "    maxperf=0\n",
    "    for c in C_range:\n",
    "        clf=select_classifier(penalty='l1', c=c)\n",
    "        y_pred=clf.decision_function(X_test)\n",
    "        perf=performance(y_test, y_pred, \"auroc\")\n",
    "        if perf>maxperf:\n",
    "            maxc=c\n",
    "            maxperf=perf\n",
    "    print(\"q3.4(a)\")\n",
    "    print(\"c=\",maxc,\"is optimal\")\n",
    "    \n",
    "    #q3.4(b)\n",
    "    plot_weight(X_train, y_train, \"l1\", C_range=C_range)\n",
    "    \n",
    "    #q4.1(b)\n",
    "    clf = select_classifier(c=0.01, class_weight={-1: 10,1 :1})\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred=clf.decision_function(X_test)\n",
    "    perf=performance(y_test, y_pred, metric=\"auroc\")\n",
    "    print(\"q4.1(b)\")\n",
    "    print(\"The auroc score is:\",perf)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    for me in metrics:\n",
    "        if me!=\"auroc\":\n",
    "            perf=performance(y_test,y_pred,metric=me)\n",
    "            print(\"The\",me,\"score is\",score)\n",
    "    \n",
    "    #q4.2(a)\n",
    "    clf = select_classifier(c=0.01, class_weight={-1: 1,1 :1})\n",
    "    clf.fit(IMB_features, IMB_labels)\n",
    "    y_pred=clf.decision_function(IMB_test_features)\n",
    "    perf=performance(IMB_test_labels, y_pred, metric=\"auroc\")\n",
    "    print(\"q4.2(a)\")\n",
    "    print(\"The auroc score is:\",perf)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    for me in metrics:\n",
    "        if me!=\"auroc\":\n",
    "            perf=performance(IMB_test_labels,y_pred,metric=me)\n",
    "            print(\"The\",me,\"score is\",score)\n",
    "\n",
    "    #q4.3(a) choose auroc\n",
    "    W_range=[-2,-1.5,-1,-0.5,0,0.5,1,1.5,2]\n",
    "    W_range=[10**w for w in W_range]\n",
    "    maxwn=0\n",
    "    maxwp=0\n",
    "    maxperf=0\n",
    "    for Wn in W_range:\n",
    "        for Wp in W_range:\n",
    "            clf = select_classifier(c=1, class_weight={-1: Wn, 1:Wp})\n",
    "            perf=cv_performance(clf, IMB_features, IMB_labels, metric=\"auroc\")\n",
    "            if perf>maxperf:\n",
    "                maxperf=perf\n",
    "                maxwn=Wn\n",
    "                maxwp=Wp\n",
    "    print(\"q4.3(a) Wn=\",maxwn,\"Wp=\",maxwp,\"is optimal\")\n",
    "    print(\"performance is:\",maxperf)\n",
    "\n",
    "    clf = select_classifier(c=1, class_weight={-1: 100, 1:100})\n",
    "    perf = cv_performance(clf,IMB_features,IMB_labels,metric=\"auroc\")\n",
    "                        \n",
    "    #q4.3(b)\n",
    "    print(\"q4.3(b)\")\n",
    "    print(\"The auroc score is\",maxperf)\n",
    "    clf = select_classifier(c=1, class_weight={-1: maxwn, 1:maxwp})\n",
    "    clf.fit(IMB_features, IMB_labels)\n",
    "    y_pred=clf.predict(IMB_test_features)\n",
    "    for me in metrics:\n",
    "        if me != \"auroc\":\n",
    "            perf=performance(IMB_test_labels, y_pred, metric=me)\n",
    "            print(\"The\",me,\"score is\",perf)\n",
    "\n",
    "    #q4.4\n",
    "    y_pred=clf.predict(IMB_test_features)\n",
    "\n",
    "    clf1=select_classifier(c=1, class_weight={-1: 1,1 :1})\n",
    "    clf1.fit(IMB_features, IMB_labels)\n",
    "    y_pred1=clf1.predict(IMB_test_features)\n",
    "    \n",
    "    \n",
    "    # Read multiclass dataange = C_range\n",
    "    # TODO: Question 5: Apply a classifier to heldout features, and then use\n",
    "    #       generate_challenge_labels to print the predicted labels\n",
    "    multiclass_features, multiclass_labels, multiclass_dictionary = get_multiclass_training_data()\n",
    "    heldout_features = get_heldout_reviews(multiclass_dictionary)\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test, dictionary_binary = get_split_binary_data()\n",
    "IMB_features, IMB_labels = get_imbalanced_data(dictionary_binary)\n",
    "IMB_test_features, IMB_test_labels = get_imbalanced_test(dictionary_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 2850\n",
      "Average number of non-zero features: 15.624\n"
     ]
    }
   ],
   "source": [
    "# q2\n",
    "print(\"Number of unique words:\",len(X_train[0]))\n",
    "print(\"Average number of non-zero features:\",np.sum(X_train)/len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dongzy/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/dongzy/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/dongzy/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/dongzy/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/dongzy/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6054342350555009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dongzy/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/dongzy/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/dongzy/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/dongzy/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/dongzy/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6054342350555009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dongzy/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/dongzy/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/dongzy/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/dongzy/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/dongzy/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6054342350555009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dongzy/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/dongzy/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/dongzy/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-db6d12686497>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mC_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mme\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmaxc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mselect_param_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mme\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mclf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mselect_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mscore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mme\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-05db24e32c5f>\u001b[0m in \u001b[0;36mselect_param_linear\u001b[0;34m(X, y, k, metric, C_range, penalty)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mC_range\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mperf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mperf\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mmaxperf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-05db24e32c5f>\u001b[0m in \u001b[0;36mcv_performance\u001b[0;34m(clf, X, y, k, metric)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"auroc\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    269\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#q3.1(c)\n",
    "mets=[\"accuracy\",\"f1-score\",\"auroc\",\"precision\",\"sensitivity\",\"specificity\"]\n",
    "selected_C=0\n",
    "C_range=[1e-3, 1e-2, 0.1,1,10,100,1000]\n",
    "for me in mets:\n",
    "    maxc=select_param_linear(X_train, Y_train, metric=me, C_range = C_range)\n",
    "    clf=select_classifier(c=maxc)\n",
    "    score=cv_performance(clf, X_train, Y_train, metric=me)\n",
    "    print(\"C=\",maxc,\"is optimal under\",me,\"metric, cv_perf=\",score)\n",
    "    if me==\"auroc\":\n",
    "        selected_C=maxc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#q3.1(d)\n",
    "clf=select_classifier(c=selected_C)\n",
    "clf.fit(X_train,Y_train)\n",
    "Y_pred = clf.decision_function(X_test)\n",
    "auroc_score=performance(Y_test, Y_pred, metric=\"auroc\")\n",
    "print(\"q3.1(d) Choose C which maximizes AUROC\")\n",
    "print(\"The AUROC score is:\",auroc_score)\n",
    "Y_pred = clf.predict(X_test)\n",
    "for me in mets:\n",
    "    if me!=\"auroc\":\n",
    "        score=performance(Y_test, Y_pred, metric=me)\n",
    "        print(\"The\",me,\"score is\",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
